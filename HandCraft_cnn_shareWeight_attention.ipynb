{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functions import *\n",
    "from pytorch_util import *\n",
    "from pytorch_models import ConvBatchLeaky1D,GRU_NCL,LambdaLayer,biasLayer,\\\n",
    "                        MultiHeadedAttention,PositionwiseFeedForward,SublayerConnection\n",
    "from torch.nn import Linear,Sequential,LeakyReLU,Dropout,L1Loss,BatchNorm1d\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from functools import partial\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## change ##\n",
    "batch_size = 16\n",
    "clip = .1\n",
    "block = ResidualBlockGLU\n",
    "normalFun = normalize_log2\n",
    "#normalFun = normalize_log\n",
    "name = 'HandCraft_cnn_shareWeight_attention'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../Data/train.csv\", \n",
    "                    dtype={'acoustic_data': np.float32, 'time_to_failure': np.float32})\n",
    "train = train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_length = 256\n",
    "window_step = 128\n",
    "\n",
    "def rolling_window(x,window_length,window_step):\n",
    "    vert_idx_list = np.arange(0, x.size - window_length, window_step)[:,np.newaxis]\n",
    "    hori_idx_list = np.arange(window_length)\n",
    "    return x[vert_idx_list + hori_idx_list]\n",
    "\n",
    "fun_list = [np.min,\n",
    "            np.max,\n",
    "            np.std,\n",
    "            np.mean,\n",
    "            partial(np.quantile,q=0.25),\n",
    "            partial(np.quantile,q=0.5),\n",
    "            partial(np.quantile,q=0.75),\n",
    "            stats.kurtosis,\n",
    "            stats.skew\n",
    "            ]\n",
    "\n",
    "fun_list = [partial(f,axis=1) for f in fun_list]\n",
    "\n",
    "def transformFun(x):\n",
    "    x = rolling_window(x,window_length,window_step)\n",
    "    x2 = np.stack([f(x) for f in fun_list],1)\n",
    "    MAE = np.mean(np.abs(x - x2[:,5:6]),1,keepdims=True)\n",
    "    return np.concatenate([x2,MAE],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def transformFun(x):\n",
    "#     x = rolling_window(x[::sample_interval],window_length,window_step)\n",
    "#     x_diff = np.diff(x)\n",
    "    \n",
    "#     x2 = np.stack([f(x) for f in fun_list],1)\n",
    "#     x2_diff = np.stack([f(x_diff) for f in fun_list],1)\n",
    "    \n",
    "#     MAE = np.mean(np.abs(x - x2[:,5:6]),1,keepdims=True)\n",
    "#     MAE_diff = np.mean(np.abs(x_diff - x2_diff[:,5:6]),1,keepdims=True)\n",
    "    \n",
    "#     return np.concatenate([x2,MAE,x2_diff,MAE_diff],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = SequenceGenTransform(train,transformFun)\n",
    "train_gen = DataLoader(train_gen,batch_size,False,num_workers=2)\n",
    "\n",
    "val_gen = SequenceGenTransform(train,transformFun,False)\n",
    "val_gen = DataLoader(val_gen,batch_size,False,num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    \"Encoder is made up of self-attn and feed forward (defined below)\"\n",
    "    def __init__(self, size, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadedAttention(2,size,dropout)\n",
    "        self.feed_forward = PositionwiseFeedForward(size,size,dropout)\n",
    "        self.sublayer = nn.ModuleList([SublayerConnection(size, dropout),SublayerConnection(size, dropout)])\n",
    "        self.size = size\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        \"Follow Figure 1 (left) for connections.\"\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))\n",
    "        return self.sublayer[1](x, self.feed_forward)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(LambdaLayer(lambda x:x.transpose(1,2)),\n",
    "                   BatchNorm1d(10),\n",
    "                   #Dropout(0.2),\n",
    "                   ConvBatchLeaky1D(10,24,5,stride=2),\n",
    "                   Dropout(0.5),\n",
    "                   ConvBatchLeaky1D(24,48,5,stride=2),\n",
    "                   Dropout(0.5),\n",
    "                   ConvBatchLeaky1D(48,96,5,stride=2),\n",
    "                   Dropout(0.5),\n",
    "                   ConvBatchLeaky1D(96,96,5,stride=2),\n",
    "                   LambdaLayer(lambda x:x.transpose(1,2)),\n",
    "                   #EncoderLayer(96,0.5),\n",
    "                   Linear(96,1,bias=False),\n",
    "                   Dropout(0.2),\n",
    "                   LambdaLayer(lambda x:x.squeeze(2).mean(1,keepdim=True)),\n",
    "                   biasLayer((1,)),\n",
    "                   LambdaLayer(lambda x:x.squeeze(1))\n",
    "                      ).to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(trainable_parameter(model),lr=2e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func_nor = loss_func_generator(L1Loss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:5.074368270543905, val_loss:5.4778547286987305\n",
      "epoch:1, train_loss:4.167447575009787, val_loss:4.23146390914917\n",
      "epoch:2, train_loss:2.953691764519765, val_loss:3.071362018585205\n",
      "epoch:3, train_loss:2.2027820514944882, val_loss:2.564425230026245\n",
      "epoch:4, train_loss:2.0741316120211897, val_loss:2.435102939605713\n",
      "Training completed in 177.57554006576538s\n"
     ]
    }
   ],
   "source": [
    "model = fit(5, model, loss_func_nor, opt, train_gen, val_gen,clip=clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../Data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen = SequenceGenTransformTest(submission.seg_id.tolist(),transformFun)\n",
    "test_gen = DataLoader(test_gen,batch_size,False,num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.iloc[:,1] = np.maximum(predict(model,test_gen),0)\n",
    "submission.to_csv('../Submission/'+name+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
