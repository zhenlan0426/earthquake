{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functions import *\n",
    "from pytorch_util import *\n",
    "from pytorch_models import ConvBatchLeaky1D,GRU_NCL,LambdaLayer,biasLayer,\\\n",
    "                        MultiHeadedAttention,PositionwiseFeedForward,SublayerConnection\n",
    "from torch.nn import Linear,Sequential,LeakyReLU,Dropout,L1Loss\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam,lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## change ##\n",
    "batch_size = 16\n",
    "clip = .1\n",
    "block = ResidualBlockGLU\n",
    "normalFun = normalize_log2\n",
    "#normalFun = normalize_log\n",
    "name = 'Spec_2d_cnn_shareWeight_attention'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../Data/train.csv\", \n",
    "                    dtype={'acoustic_data': np.float32, 'time_to_failure': np.float32})\n",
    "train = train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = SequenceGenSpec(train,normalFun=normalFun)\n",
    "#train_gen = mixupWrapper(SequenceGenSpec(train),4e-2) # does not improve\n",
    "train_gen = DataLoader(train_gen,batch_size,False,num_workers=2)\n",
    "\n",
    "val_gen = SequenceGenSpec(train,False,normalFun=normalFun)\n",
    "val_gen = DataLoader(val_gen,batch_size,False,num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(train_gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 129, 780])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "258/2/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    \"Encoder is made up of self-attn and feed forward (defined below)\"\n",
    "    def __init__(self, size, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadedAttention(2,size,dropout)\n",
    "        self.feed_forward = PositionwiseFeedForward(size,size,dropout)\n",
    "        self.sublayer = nn.ModuleList([SublayerConnection(size, dropout),SublayerConnection(size, dropout)])\n",
    "        self.size = size\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        \"Follow Figure 1 (left) for connections.\"\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))\n",
    "        return self.sublayer[1](x, self.feed_forward)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(Dropout(0.5),\n",
    "                   ConvBatchLeaky1D(129,256,5,stride=2),\n",
    "                   LambdaLayer(lambda x:x.transpose(1,2)),\n",
    "                   EncoderLayer(256,0.5),\n",
    "                   Linear(256,1,bias=False),\n",
    "                   Dropout(0.2),\n",
    "                   LambdaLayer(lambda x:x.squeeze(2).mean(1,keepdim=True)),\n",
    "                   biasLayer((1,)),\n",
    "                   LambdaLayer(lambda x:x.squeeze(1))\n",
    "                      ).to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(trainable_parameter(model),lr=2e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func_nor = loss_func_generator(L1Loss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:2.3939479486300397, val_loss:2.4598631858825684\n",
      "epoch:1, train_loss:2.1571697506767054, val_loss:2.4444499015808105\n",
      "epoch:2, train_loss:2.1166211028511706, val_loss:2.5073161125183105\n",
      "epoch:3, train_loss:2.124555957431977, val_loss:2.4908926486968994\n",
      "epoch:4, train_loss:2.0987318232655525, val_loss:2.495560646057129\n",
      "Training completed in 27.856075286865234s\n"
     ]
    }
   ],
   "source": [
    "model = fit(5, model, loss_func_nor, opt, train_gen, val_gen,clip=clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_submission(name,model,normalFun,batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
