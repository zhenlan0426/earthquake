{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functions import *\n",
    "from pytorch_util import *\n",
    "from pytorch_models import ConvBatchLeaky1D,GRU_NCL,SincConv_fast,LambdaLayer,biasLayer\n",
    "from torch.nn import Linear,Sequential,LeakyReLU,Dropout,L1Loss\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "## change ##\n",
    "batch_size = 32\n",
    "clip = .1\n",
    "block = ResidualBlock\n",
    "normalFun = normalize2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../Data/train.csv\", \n",
    "                    dtype={'acoustic_data': np.float32, 'time_to_failure': np.float32})\n",
    "train = train.values\n",
    "train[:,0] = normalFun(train[:,0])\n",
    "# without tanh is worse-off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_gen = SequenceGen(train)\n",
    "# train_gen = DataLoader(train_gen,batch_size,False,num_workers=2)\n",
    "\n",
    "# val_gen = SequenceGen(train,False)\n",
    "# val_gen = DataLoader(val_gen,batch_size,False,num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = SequenceGenSample(train)\n",
    "train_gen = DataLoader(train_gen,batch_size,False,num_workers=2)\n",
    "\n",
    "val_gen = SequenceGenSample(train,False)\n",
    "val_gen = DataLoader(val_gen,batch_size,False,num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(SincConv_fast(64,128,sample_rate=100000,stride=64),\n",
    "                      block(64),\n",
    "                      Dropout(0.5),\n",
    "                      block(128),\n",
    "                      Dropout(0.5),                 \n",
    "                      LambdaLayer(lambda x:x.transpose(1,2)),\n",
    "                      Linear(256,1,bias=False),\n",
    "                      LeakyReLU(0.2,True),\n",
    "                      LambdaLayer(lambda x:x.squeeze(2).mean(1,keepdim=True)),\n",
    "                      #LambdaLayer(lambda x:x.squeeze(2).median(1,keepdim=True)[0]),                   \n",
    "                      biasLayer((1,)),\n",
    "                      #Linear(1,1),\n",
    "                      LambdaLayer(lambda x:x.squeeze(1))\n",
    "                      ).to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(trainable_parameter(model),lr=4e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func_nor = loss_func_generator(L1Loss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:4.5943815524761495, val_loss:4.678011894226074\n",
      "epoch:1, train_loss:3.096679225564003, val_loss:3.295793294906616\n",
      "epoch:2, train_loss:2.2941563840095816, val_loss:3.318624258041382\n",
      "epoch:3, train_loss:2.1509709667700987, val_loss:2.5512492656707764\n",
      "epoch:4, train_loss:2.092960469997846, val_loss:2.4404022693634033\n",
      "Training completed in 9.100494623184204s\n"
     ]
    }
   ],
   "source": [
    "model = fit(5, model, loss_func_nor, opt, train_gen, val_gen,clip=clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss:2.0531784983781667, val_loss:2.588535785675049\n",
      "epoch:1, train_loss:2.0186399668455124, val_loss:2.4619321823120117\n",
      "epoch:2, train_loss:2.0004457178024144, val_loss:2.3914332389831543\n",
      "epoch:3, train_loss:1.9703149016086872, val_loss:2.677093744277954\n",
      "epoch:4, train_loss:1.943378393466656, val_loss:2.5897536277770996\n",
      "Training completed in 8.98228120803833s\n"
     ]
    }
   ],
   "source": [
    "model = fit(5, model, loss_func_nor, opt, train_gen, val_gen,clip=clip,lossBest=2.44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../Data/sample_submission.csv',)\n",
    "test_gen = SequenceGenTestSample(submission.seg_id.tolist(),normalFun)\n",
    "test_gen = DataLoader(test_gen,batch_size,False,num_workers=2)\n",
    "yhat = predict(model,test_gen)\n",
    "submission.iloc[:,1] = np.median(yhat.reshape(-1,4),1)\n",
    "submission.to_csv('../Submission/sub_raw_shareWeight_sample_SincNet.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
